scale_colour_manual(name="dependency", values=c('#648fff', '#ffb000'), labels=c("gap", "resumption")),
scale_shape_manual(name="dependency", values=c(16, 15), labels=c("gap", "resumption")),
theme(text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = .5),
legend.position = "none",
legend.margin=margin(0, 0, 0, 0),
legend.box.margin = margin(0, 0, 0, 0)),
facet_wrap(~panel)
)
p1 + s
bucld2 <- p1 + s +
labs(caption = 'glmer: accuracy ~ dependency * environment +\n(1 + dependency * environment | person) +\n(1 + dependency * environment | item)', hjust = .5) +
theme(plot.caption = element_text(hjust = .5))
bucld2
# create plot
s <- list(
geom_line(lwd = 1),
geom_point(size = 2),
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, lwd=1, linetype=1),
theme_classic(),
scale_x_discrete(name="environment", limits = c("short", "long", "island"), labels = c("short", "long", "island")),
scale_y_continuous(name="% accuracy", limits=c(68, 100)),
scale_colour_manual(name="dependency", values=c('#648fff', '#ffb000'), labels=c("gap", "resumption")),
scale_shape_manual(name="dependency", values=c(16, 15), labels=c("gap", "resumption")),
theme(text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = .5),
legend.position = "none",
axis.title.y = element_text(margin=margin(r=-1)),
legend.margin=margin(0, 0, 0, 0),
legend.box.margin = margin(0, 0, 0, 0)),
facet_wrap(~panel)
)
p1 + s
bucld2 <- p1 + s +
labs(caption = 'glmer: accuracy ~ dependency * environment +\n(1 + dependency * environment | person) +\n(1 + dependency * environment | item)', hjust = .5) +
theme(plot.caption = element_text(hjust = .5))
# create plot
s <- list(
geom_line(lwd = 1),
geom_point(size = 2),
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, lwd=1, linetype=1),
theme_classic(),
scale_x_discrete(name="environment", limits = c("short", "long", "island"), labels = c("short", "long", "island")),
scale_y_continuous(name="% accuracy", limits=c(68, 100)),
scale_colour_manual(name="dependency", values=c('#648fff', '#ffb000'), labels=c("gap", "resumption")),
scale_shape_manual(name="dependency", values=c(16, 15), labels=c("gap", "resumption")),
theme(text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = .5),
legend.position = "none",
axis.title.y = element_text(margin=margin(r=-2)),
legend.margin=margin(0, 0, 0, 0),
legend.box.margin = margin(0, 0, 0, 0)),
facet_wrap(~panel)
)
p1 + s
# create plot
s <- list(
geom_line(lwd = 1),
geom_point(size = 2),
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, lwd=1, linetype=1),
theme_classic(),
scale_x_discrete(name="environment", limits = c("short", "long", "island"), labels = c("short", "long", "island")),
scale_y_continuous(name="% accuracy", limits=c(68, 100)),
scale_colour_manual(name="dependency", values=c('#648fff', '#ffb000'), labels=c("gap", "resumption")),
scale_shape_manual(name="dependency", values=c(16, 15), labels=c("gap", "resumption")),
theme(text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = .5),
legend.position = "none",
axis.title.y = element_text(margin=margin(r=-5)),
legend.margin=margin(0, 0, 0, 0),
legend.box.margin = margin(0, 0, 0, 0)),
facet_wrap(~panel)
)
p1 + s
# create plot
s <- list(
geom_line(lwd = 1),
geom_point(size = 2),
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, lwd=1, linetype=1),
theme_classic(),
scale_x_discrete(name="environment", limits = c("short", "long", "island"), labels = c("short", "long", "island")),
scale_y_continuous(name="% accuracy", limits=c(68, 100)),
scale_colour_manual(name="dependency", values=c('#648fff', '#ffb000'), labels=c("gap", "resumption")),
scale_shape_manual(name="dependency", values=c(16, 15), labels=c("gap", "resumption")),
theme(text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = .5),
legend.position = "none",
axis.title.y = element_text(margin=margin(r=-3)),
legend.margin=margin(0, 0, 0, 0),
legend.box.margin = margin(0, 0, 0, 0)),
facet_wrap(~panel)
)
p1 + s
bucld2 <- p1 + s +
labs(caption = 'glmer: accuracy ~ dependency * environment +\n(1 + dependency * environment | person) +\n(1 + dependency * environment | item)', hjust = .5) +
theme(plot.caption = element_text(hjust = .5))
bucld2
trim <- trim %>%
mutate(region = as.numeric(region)) %>%
mutate(region2 = case_when(study == '210510_do' ~ region - 11,
study == '210510_su' & environment %in% c('short', 'long') ~ region - 8,
study == '210510_su' & environment == 'island' ~ region - 10))
md <- trim %>%
filter(region2 %in% c('1', '2', '3')) %>%
mutate(logrt = log(rt)) %>%
group_by(study, group, participant, item, environment, dependency) %>%
summarise(logrt = mean(logrt)) %>%
ungroup()
md <- md %>%
filter(study == '210510_do')
# summarise for plotting with logrts
plot <- md %>%
group_by(group, environment, dependency) %>%
summarise(mean = mean(logrt, na.rm=T),
sd = sd(logrt, na.rm=T),
n = n()) %>%
mutate(se = sd / sqrt(n),
ci = qt(1 - (0.05 / 2), n - 1) * se) %>%
ungroup()
# facet labels
groups <- c(`english` = 'ENS', `korean` = 'KLE', `mandarin` = 'MLE')
# generate plot
p <- ggplot(data=plot, aes(x=environment, y=mean, group=dependency, col=dependency, shape=dependency)) +
geom_line(lwd=1) +
geom_point(size=2) +
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.5, lwd=1, linetype=1) +
theme_classic() +
scale_y_continuous(name="logRT", limits=c(5.75, 6.15)) +
scale_x_discrete(name="environment", limits=c("short", "long", "island")) +
scale_colour_manual(name="dependency", values=c('#648fff', '#ffb000'), limits=c('gap', 'pronoun'), labels=c('gap', 'resumption')) +
scale_shape_manual(name="dependency", values=c(16, 15), limits=c('gap', 'pronoun'), labels=c('gap', 'resumption')) +
theme(text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = .5),
legend.position = 'right',
legend.margin = margin(0, .1, 0, -.1, 'cm'),
legend.box.margin = margin(0, .1, 0, -.1, 'cm'),
plot.margin = margin(0, 0, 0, 0, 'cm')) +
facet_wrap(~group, labeller = as_labeller(groups))
p
bucld1 <- p +
labs(caption = 'lmer: logRT ~ dependency * environment +\n(1 + dependency * environment | person) +\n(1 + dependency * environment | item)', hjust = .5) +
theme(plot.caption = element_text(hjust = .5))
bucld1
bucld1 + bucld2 +  plot_layout(widths = c(1, 1)) +
theme(plot.margin = margin(0, 0, 0, 0, "cm"))
ggsave("plots/orc/bucld.png", width=9.3, height=2.5, dpi=600)
# filter to critical trials
ds <- spr %>%
filter(!condition %in% c('grammatical', 'ungrammatical')) %>%
mutate(rt = as.numeric(as.character(rt)),
participant = as.factor(participant))
# run fct_drop on 'participant'
ds <- ds %>%
mutate(participant = fct_drop(participant))
# check participants
check <- ds %>%
group_by(study, group, participant) %>%
summarise() %>%
summarise(n = n()) %>%
ungroup()
View(check)
# check participants
check <- spr %>%
group_by(study, group, participant) %>%
summarise() %>%
summarise(n = n()) %>%
ungroup()
ajt <- df %>%
filter(task %in% c('english_ajt', 'korean_ajt', 'mandarin_ajt')) %>%
arrange(study, group, participant) %>%
select_if(function(x){!all(is.na(x))})
check <- ajt %>%
filter(!response %in% c(1, 2, 3, 4, 5, 6))
ajt <- ajt %>%
filter(is.na(response) == FALSE)
ajt <- ajt %>%
mutate(acceptance = case_when(response > 3.5 ~ TRUE,
response < 3.5 ~ FALSE))
ajt <- ajt %>%
mutate(response = as.numeric(response)) %>%
group_by(study, group, task, participant) %>%
mutate(zscore = (response - mean(response, na.rm=T)) / sd(response, na.rm = T)) %>%
ungroup()
check <- ajt %>%
mutate(condition = as.factor(condition))
summary(check$condition)
temp <- ajt %>%
filter(condition %in% c('grammatical', 'ungrammatical')) %>%
mutate(accuracy = as.logical(accuracy)) %>%
group_by(study, group, task, participant) %>%
summarise(acc_rate = mean(accuracy, na.rm = T)) %>%
ungroup()
ggplot(temp, aes(x=group, y=acc_rate, fill=group, label=participant)) +
geom_hline(yintercept=.5) +
geom_violin() +
geom_boxplot(width = .1, fill='white') +
theme_classic() +
scale_x_discrete(name="group",
limits = c('english', 'korean', 'mandarin'),
labels = c('ENS', 'KLE', 'MLE')) +
scale_y_continuous(name="accuracy rate",
limits=c(0, 1)) +
theme(text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = .5),
legend.position = "hide") +
facet_wrap(~task)
ajt <- ajt %>%
left_join(temp, by = c('study', 'group', 'task', 'participant')) %>%
filter(acc_rate > .5)
plot <- ajt %>%
group_by(group, task, participant, acc_rate) %>%
summarise() %>%
ungroup()
ggplot(plot, aes(x=group, y=acc_rate, fill=group, label=participant)) +
geom_hline(yintercept=.5) +
geom_violin() +
geom_boxplot(width = .1, fill='white') +
theme_classic() +
scale_x_discrete(name="group",
limits = c('english', 'korean', 'mandarin'),
labels = c('ENS', 'KLE', 'MLE')) +
scale_y_continuous(name="accuracy rate",
limits=c(0, 1)) +
theme(text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = .5),
legend.position = "hide") +
facet_wrap(~task)
check <- ajt %>%
group_by(study, group, participant) %>%
summarise() %>%
ungroup() %>%
group_by(study, group) %>%
summarise(n = n()) %>%
ungroup()
check <- ajt %>%
group_by(study, group, task, participant) %>%
summarise() %>%
ungroup() %>%
group_by(study, group) %>%
summarise(n = n()) %>%
ungroup()
View(ajt)
check <- ajt %>%
group_by(study, group, task, participant) %>%
summarise() %>%
ungroup() %>%
group_by(study, group, task) %>%
summarise(n = n()) %>%
ungroup()
check <- ajt %>%
group_by(study, task, group, participant) %>%
summarise() %>%
ungroup() %>%
group_by(study, task, group) %>%
summarise(n = n()) %>%
ungroup()
# check participants
check <- ds %>%
group_by(study, group, participant) %>%
summarise() %>%
summarise(n = n()) %>%
ungroup()
# check participants
check <- spr %>%
group_by(study, group, participant) %>%
summarise() %>%
summarise(n = n()) %>%
ungroup()
check <- ct %>%
group_by(study, group, participant) %>%
summarise() %>%
ungroup() %>%
group_by(study, group) %>%
summarise(n = n()) %>%
ungroup()
# load packages
library(tidyverse) # for data processing
library(lmerTest) # for mixed-effects modeling
library(readxl) # for reading .xlsx files
library(base64enc) # for converting recordings from base64 to audio files
library(stringdist) # for calculating edit distance on c-test responses
library(hunspell) # for spell checking of c-test responses
library(patchwork) # for plotting
library(jsonlite) # for unpacking json
library(beepr) # for notifications
library(tictoc) # for timing operations
library(ggh4x) # for plotting
library(emmeans) #  for post-hoc tests; see https://marissabarlaz.github.io/portfolio/contrastcoding/
df <- read_csv('data/data.csv', col_types = cols(.default = 'c')) %>%
select(-audio_data)
ct <- read_csv('data/ctest_scored.csv', col_types = cols(.default = 'f', accuracy = 'l'))
survey <- df %>%
filter(task == 'language_survey') %>%
arrange(study, group, participant) %>%
select_if(function(x){!all(is.na(x))})
lor <- read_csv('data/length_of_residence.csv', col_types = cols(.default = 'f', accuracy = 'l'))
View(lor)
temp <- read_csv('data/length_of_residence.csv', col_types = cols(.default = 'f', accuracy = 'l'))
rm(temp)
lor <- read_csv('data/length_of_residence.csv', col_types = cols(.default = 'f', accuracy = 'l'))
View(survey)
check <- survey %>%
left_join(lor, by = participant) %>%
mutate(lor = as.numeric(lor)) %>%
group_by(study, group, participant) %>%
summarise() %>%
ungroup() %>%
group_by(study, group) %>%
summarise(mean = mean(lor, na.rm = TRUE),
sd = sd(lor, na.rm = TRUE),
min = min(lor, na.rm = TRUE),
max = max(lor, na.rm = TRUE))
check <- survey %>%
left_join(lor, by = 'participant') %>%
mutate(lor = as.numeric(lor)) %>%
group_by(study, group, participant) %>%
summarise() %>%
ungroup() %>%
group_by(study, group) %>%
summarise(mean = mean(lor, na.rm = TRUE),
sd = sd(lor, na.rm = TRUE),
min = min(lor, na.rm = TRUE),
max = max(lor, na.rm = TRUE))
check <- survey %>%
left_join(lor, by = 'participant') %>%
mutate(lor = as.numeric(lor)) %>%
group_by(study, group, participant) %>%
summarise() %>%
ungroup()
View(check)
check <- survey %>%
left_join(lor, by = 'participant') %>%
mutate(lor = as.numeric(lor)) %>%
group_by(study, group, participant, lor) %>%
summarise() %>%
ungroup() %>%
group_by(study, group) %>%
summarise(mean = mean(lor, na.rm = TRUE),
sd = sd(lor, na.rm = TRUE),
min = min(lor, na.rm = TRUE),
max = max(lor, na.rm = TRUE)) %>%
ungroup()
lor <- lor %>%
mutate(study = case_when(str_detect(participant, 'do') == TRUE ~ '210510_do',
str_detect(participant, 'su') == TRUE ~ '210510_su'),
group = case_when(str_detect(participant, 'en') == TRUE ~ 'english',
str_detect(participant, 'ko') == TRUE ~ 'korean',
str_detect(participant, 'zh') == TRUE ~ 'mandarin'))
lor <- read_csv('data/length_of_residence.csv', col_types = cols(.default = 'f', accuracy = 'l'))
lor <- lor %>%
mutate(study = case_when(str_detect(participant, 'do') == TRUE ~ '210510_do',
str_detect(participant, 'su') == TRUE ~ '210510_su'),
group = case_when(str_detect(participant, 'en') == TRUE ~ 'english',
str_detect(participant, 'ko') == TRUE ~ 'korean',
str_detect(participant, 'zh') == TRUE ~ 'mandarin')) %>%
select(study, group, participant, lor) %>%
mutate(lor = as.numeric(lor))
lor <- lor %>%
mutate(study = case_when(str_detect(participant, 'do') == TRUE ~ '210510_do',
str_detect(participant, 'su') == TRUE ~ '210510_su'),
group = case_when(str_detect(participant, 'en') == TRUE ~ 'english',
str_detect(participant, 'ko') == TRUE ~ 'korean',
str_detect(participant, 'zh') == TRUE ~ 'mandarin')) %>%
select(study, group, participant, lor) %>%
mutate(lor = as.numeric(as.character(lor)))
lor <- read_csv('data/length_of_residence.csv', col_types = cols(.default = 'f', accuracy = 'l'))
lor <- lor %>%
mutate(study = case_when(str_detect(participant, 'do') == TRUE ~ '210510_do',
str_detect(participant, 'su') == TRUE ~ '210510_su'),
group = case_when(str_detect(participant, 'en') == TRUE ~ 'english',
str_detect(participant, 'ko') == TRUE ~ 'korean',
str_detect(participant, 'zh') == TRUE ~ 'mandarin')) %>%
select(study, group, participant, lor) %>%
mutate(lor = as.numeric(as.character(lor)))
lor <- lor %>%
mutate(study = case_when(str_detect(participant, 'do') == TRUE ~ '210510_do',
str_detect(participant, 'su') == TRUE ~ '210510_su'),
group = case_when(str_detect(participant, 'en') == TRUE ~ 'english',
str_detect(participant, 'ko') == TRUE ~ 'korean',
str_detect(participant, 'zh') == TRUE ~ 'mandarin')) %>%
select(study, group, participant, lor) %>%
mutate(lor = as.numeric(as.character(lor)))
lor <- read_csv('data/length_of_residence.csv', col_types = cols(.default = 'f', accuracy = 'l'))
lor <- lor %>%
mutate(study = case_when(str_detect(participant, 'do') == TRUE ~ '210510_do',
str_detect(participant, 'su') == TRUE ~ '210510_su'),
group = case_when(str_detect(participant, 'en') == TRUE ~ 'english',
str_detect(participant, 'ko') == TRUE ~ 'korean',
str_detect(participant, 'zh') == TRUE ~ 'mandarin')) %>%
select(study, group, participant, lor) %>%
mutate(lor = as.numeric(as.character(lor))) %>%
group_by(study, group) %>%
summarise(mean = mean(lor, na.rm = TRUE),
sd = sd(lor, na.rm = TRUE),
min = min(lor, na.rm = TRUE),
max = max(lor, na.rm = TRUE)) %>%
ungroup()
lor <- read_csv('data/length_of_residence.csv', col_types = cols(.default = 'f', accuracy = 'l'))
lor <- lor %>%
mutate(study = case_when(str_detect(participant, 'do') == TRUE ~ '210510_do',
str_detect(participant, 'su') == TRUE ~ '210510_su'),
group = case_when(str_detect(participant, 'en') == TRUE ~ 'english',
str_detect(participant, 'ko') == TRUE ~ 'korean',
str_detect(participant, 'zh') == TRUE ~ 'mandarin')) %>%
select(study, group, participant, lor) %>%
mutate(lor = as.numeric(as.character(lor)))
lor <- lor %>%
group_by(study, group) %>%
summarise(mean = mean(lor, na.rm = TRUE),
sd = sd(lor, na.rm = TRUE),
min = min(lor, na.rm = TRUE),
max = max(lor, na.rm = TRUE)) %>%
ungroup()
age <- survey %>%
filter(item == 'age') %>%
mutate(response = as.numeric(response)) %>%
group_by(study, group) %>%
summarise(mean = mean(response, na.rm = TRUE),
sd = sd(response, na.rm = TRUE),
min = min(response, na.rm = TRUE),
max = max(response, na.rm = TRUE)) %>%
ungroup()
View(age)
rm(age)
aoa <- survey %>%
filter(item == 'english_aoa') %>%
mutate(response = as.numeric(response)) %>%
group_by(study, group) %>%
summarise(mean = mean(response, na.rm = TRUE),
sd = sd(response, na.rm = TRUE),
min = min(response, na.rm = TRUE),
max = max(response, na.rm = TRUE)) %>%
ungroup()
View(aoa)
# load packages
library(tidyverse) # for data processing
library(lmerTest) # for mixed-effects modeling
library(readxl) # for reading .xlsx files
library(base64enc) # for converting recordings from base64 to audio files
library(stringdist) # for calculating edit distance on c-test responses
library(hunspell) # for spell checking of c-test responses
library(patchwork) # for plotting
library(jsonlite) # for unpacking json
library(beepr) # for notifications
library(tictoc) # for timing operations
library(ggh4x) # for plotting
library(emmeans) #  for post-hoc tests; see https://marissabarlaz.github.io/portfolio/contrastcoding/
df <- read_csv('data/data.csv', col_types = cols(.default = 'c')) %>%
select(-audio_data)
ct <- read_csv('data/ctest_scored.csv', col_types = cols(.default = 'f', accuracy = 'l'))
check <- ct %>%
group_by(study, group, participant) %>%
summarise() %>%
ungroup() %>%
group_by(study, group) %>%
summarise(n = n()) %>%
ungroup()
plot <- ct %>%
group_by(study, group, participant) %>%
summarise(accuracy = mean(accuracy)) %>%
ungroup()
check <- plot %>%
group_by(study, group) %>%
summarise(mean = mean(accuracy),
min = min(accuracy),
max = max(accuracy)) %>%
ungroup()
check <- ct %>%
group_by(study, group) %>%
summarise(mean = mean(accuracy)) %>%
ungroup()
p1 <- ggplot(data=filter(plot, study == '210510_do'), aes(x=group, y=accuracy*100, fill=group, label=participant))
p2 <- ggplot(data=filter(plot, study == '210510_su'), aes(x=group, y=accuracy*100, fill=group, label=participant))
s <- list(
geom_hline(yintercept=50),
geom_violin(fill = 'lightblue'),
geom_boxplot(width = .1, fill='white'),
#geom_jitter(size=1, shape=1, alpha=.25, position = position_jitter(seed=2, width=.15)),
#geom_text(size = 2.5, col = "black", position = position_jitter(seed=2)),
theme_classic(),
scale_x_discrete(name="group",
limits = c('english', 'korean', 'mandarin'), labels = c('ENS', 'KLE', 'MLE')),
scale_y_continuous(name="% accuracy",
limits=c(0, 100)),
theme(text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = .5),
legend.position = "hide")
)
p1 + s +
geom_hline(yintercept = 85.48) +
geom_hline(yintercept = 58.58) +
geom_hline(yintercept = 57.71)
p1 + s
View(ct)
md <- ct %>%
filter(study == '210510_do')
contrasts(md$group)
model1 <- glmer(accuracy ~ group + (1 + group | participant) + (1 + group | item),
data = md, family = binomial, control = glmerControl(optimizer = "bobyqa"))
summary(model1)
beepr::beep(1)
model1 <- glmer(accuracy ~ group + (1 | participant) + (1 + group | item),
data = md, family = binomial, control = glmerControl(optimizer = "bobyqa"))
summary(model1)
beepr::beep(1)
md <- md %>%
mutate(group = fct_relevel(group, 'korean', 'mandarin', 'english'))
contrasts(md$group)
model1 <- glmer(accuracy ~ group + (1 | participant) + (1 + group | item),
data = md, family = binomial, control = glmerControl(optimizer = "bobyqa"))
summary(model1)
beepr::beep(1)
